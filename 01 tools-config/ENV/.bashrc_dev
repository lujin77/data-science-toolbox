# added by Anaconda2 4.1.1 installer
export PATH="/Users/lujin/anaconda/bin:$PATH"

# java
export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home
export CLASS_PATH=$JAVA_HOME/lib
export PATH=$PATH:$JAVA_HOME/bin

export GOPATH=/Users/lujin/Code/go
export GOBIN=$GOPATH/bin

# scala
export PATH=$PATH:/usr/local/Cellar/scala/2.11.8/bin

# maven
#export M2_HOME=/usr/local/opt/maven
#export M2=$M2_HOME/bin
#export PATH=$M2:$PATH


alias ctags="`brew --prefix`/bin/ctags"

# bigdata
export HADOOP_PREFIX=/usr/local/Cellar/hadoop/2.7.3/libexec
export PATH=$PATH:$HADOOP_PREFIX/bin
export PATH=$PATH:$HADOOP_PREFIX/sbin
export HADOOP_MAPRED_HOMD=${HADOOP_PREFIX}
export HADOOP_COMMON_HOME=${HADOOP_PREFIX}
export HADOOP_HDFS_HOME=${HADOOP_PREFIX}
export YARN_HOME=${HADOOP_PREFIX}
export HADOOP_CONF_DIR=${HADOOP_PREFIX}/etc/hadoop
export HDFS_CONF_DIR=${HADOOP_PREFIX}/etc/hadoop
export YARN_CONF_DIR=${HADOOP_PREFIX}/etc/hadoop

export SPARK_HOME=/usr/local/Cellar/apache-spark/2.0.0/libexec

# For a ipython notebook and pyspark integration
if which pyspark > /dev/null; then
  export SPARK_HOME="/usr/local/Cellar/apache-spark/2.0.0/libexec/"
  export PYSPARK_SUBMIT_ARGS="--master local[2]"
fi

export STORM_HOME=/usr/local/Cellar/storm/1.0.1/libexec

# logstash
export PATH=$PATH:/Users/lujin/sofeware/logstash-2.4.0/bin

export PKG_CONFIG_PATH=/usr/local/Cellar/zeromq/4.1.5/lib/pkgconfig

export SBT_OPTS=-Dsbt.override.build.repos=true
